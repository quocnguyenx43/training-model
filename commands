TASK 1: ####################################
+ vinai/phobert-base / 200
    + python run_train_cls_task.py --task "task-1" --model_type "simple" --model_name "vinai/phobert-base" --source_len 200 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-1" --model_type "simple" --model_name "vinai/phobert-base" --source_len 200 --batch_size 16

+ uitnlp/visobert / 400
    + python run_train_cls_task.py --task "task-1" --model_type "simple" --model_name "uitnlp/visobert" --source_len 400 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-1" --model_type "simple" --model_name "uitnlp/visobert" --source_len 400 --batch_size 16

+ uitnlp/CafeBERT / 300
    + python run_train_cls_task.py --task "task-1" --model_type "simple" --model_name "uitnlp/CafeBERT" --source_len 300 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-1" --model_type "simple" --model_name "uitnlp/CafeBERT" --source_len 300 --batch_size 16

+ xlm-roberta-base / 500
    + python run_train_cls_task.py --task "task-1" --model_type "simple" --model_name "xlm-roberta-base" --source_len 500 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-1" --model_type "simple" --model_name "xlm-roberta-base" --source_len 500 --batch_size 16

+ bert-base-multilingual-cased / 500
    + python run_train_cls_task.py --task "task-1" --model_type "simple" --model_name "bert-base-multilingual-cased" --source_len 500 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-1" --model_type "simple" --model_name "bert-base-multilingual-cased" --source_len 500 --batch_size 16

+ distilbert-base-multilingual-cased / 500
    + python run_train_cls_task.py --task "task-1" --model_type "simple" --model_name "distilbert-base-multilingual-cased" --source_len 500 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-1" --model_type "simple" --model_name "distilbert-base-multilingual-cased" --source_len 500 --batch_size 16



TASK 2: ####################################
+ vinai/phobert-base / 200
    + python run_train_cls_task.py --task "task-2" --model_type "simple" --model_name "vinai/phobert-base" --source_len 200 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-2" --model_type "simple" --model_name "vinai/phobert-base" --source_len 200 --batch_size 16

+ uitnlp/visobert / 400
    + python run_train_cls_task.py --task "task-2" --model_type "simple" --model_name "uitnlp/visobert" --source_len 400 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-2" --model_type "simple" --model_name "uitnlp/visobert" --source_len 400 --batch_size 16

+ uitnlp/CafeBERT / 300
    + python run_train_cls_task.py --task "task-2" --model_type "simple" --model_name "uitnlp/CafeBERT" --source_len 300 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-2" --model_type "simple" --model_name "uitnlp/CafeBERT" --source_len 300 --batch_size 16

+ xlm-roberta-base / 500
    + python run_train_cls_task.py --task "task-2" --model_type "simple" --model_name "xlm-roberta-base" --source_len 500 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-2" --model_type "simple" --model_name "xlm-roberta-base" --source_len 500 --batch_size 16

+ bert-base-multilingual-cased / 500
    + python run_train_cls_task.py --task "task-2" --model_type "simple" --model_name "bert-base-multilingual-cased" --source_len 500 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-2" --model_type "simple" --model_name "bert-base-multilingual-cased" --source_len 500 --batch_size 16

+ distilbert-base-multilingual-cased / 500
    + python run_train_cls_task.py --task "task-2" --model_type "simple" --model_name "distilbert-base-multilingual-cased" --source_len 500 --batch_size 16 --learning_rate 0.001 --epochs 20
    + python run_evaluation_cls_task.py --task "task-2" --model_type "simple" --model_name "distilbert-base-multilingual-cased" --source_len 500 --batch_size 16



TASK 3: ####################################
+ VietAI/vit5-base
    + python run_train_generation_task_finetune.py --task "task-3" --model_name "VietAI/vit5-base" --source_len 1024 --target_len 512 --batch_size 4 --learning_rate 0.001 --epochs 3
    # + python run_eval_task_3_fine_tune.py --model_name "VietAI/vit5-base" --source_len 512 --target_len 256 --batch_size 16 --learning_rate 0.001 --epochs 2