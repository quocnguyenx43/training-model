vinai/phobert-base
[11:42:50] task: task-1                                                                                 my_import.py:91
           model_type: simple                                                                           my_import.py:91
           model_name: vinai/phobert-base                                                               my_import.py:91
           padding_len: 200                                                                             my_import.py:85
           batch_size: 32                                                                               my_import.py:91
           learning_rate: 0.001                                                                         my_import.py:91
           epochs: 10                                                                                   my_import.py:91
           device: cuda                                                                                 my_import.py:91
           saving_path: ./models/task_1/simple_phobert-base                                             my_import.py:91
           train_shape: (8444, 28)                                                                      my_import.py:91
           dev_shape: (1207, 28)                                                                        my_import.py:91
           test_shape: (2413, 28)                                                                       my_import.py:91


model_weight_path: ./models/task_1/simple_phobert-base_4.pth
Loading model weight successfully!

Evaluation on dev set
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:07<00:00,  5.18it/s]
Evaluation, Loss: 36.7971, Acc: 0.5402, Precision: 0.5944, Recall: 0.4726, F1: 0.4574

Confusion Matrix:
[[464  33  22]
 [227 140  14]
 [235  24  48]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.50      0.89      0.64       519
     warning       0.71      0.37      0.48       381
     seeding       0.57      0.16      0.25       307
    accuracy                           0.54      1207

   macro avg       0.59      0.47      0.46      1207
weighted avg       0.59      0.54      0.49      1207

Evaluation on test set
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:08<00:00,  8.80it/s]
Evaluation, Loss: 73.9249, Acc: 0.5234, Precision: 0.5663, Recall: 0.4671, F1: 0.4502

Confusion Matrix:
[[881  77  41]
 [470 271  60]
 [456  46 111]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.49      0.88      0.63       999
     warning       0.69      0.34      0.45       801
     seeding       0.52      0.18      0.27       613
    accuracy                           0.52      2413

   macro avg       0.57      0.47      0.45      2413
weighted avg       0.56      0.52      0.48      2413



uitnlp/visobert
[11:43:23] task: task-1                                                                                 my_import.py:91
           model_type: simple                                                                           my_import.py:91
           model_name: uitnlp/visobert                                                                  my_import.py:91
           padding_len: 400                                                                             my_import.py:85
           batch_size: 32                                                                               my_import.py:91
           learning_rate: 0.001                                                                         my_import.py:91
           epochs: 10                                                                                   my_import.py:91
           device: cuda                                                                                 my_import.py:91
           saving_path: ./models/task_1/simple_visobert                                                 my_import.py:91
           train_shape: (8444, 28)                                                                      my_import.py:91
           dev_shape: (1207, 28)                                                                        my_import.py:91
           test_shape: (2413, 28)                                                                       my_import.py:91

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/visobert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.



model_weight_path: ./models/task_1/simple_visobert_7.pth
Loading model weight successfully!

Evaluation on dev set
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:09<00:00,  5.16it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:09<00:00,  3.85it/s]
Evaluation, Loss: 35.4555, Acc: 0.5584, Precision: 0.5601, Recall: 0.5016, F1: 0.4951

Confusion Matrix:
[[434  47  38]
 [172 179  30]
 [206  40  61]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.53      0.84      0.65       519
     warning       0.67      0.47      0.55       381
     seeding       0.47      0.20      0.28       307
    accuracy                           0.56      1207

   macro avg       0.56      0.50      0.50      1207
weighted avg       0.56      0.56      0.53      1207

Evaluation on test set
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:15<00:00,  4.77it/s]
Evaluation, Loss: 70.6348, Acc: 0.5562, Precision: 0.5635, Recall: 0.5084, F1: 0.5028

Confusion Matrix:
[[834 106  59]
 [352 361  88]
 [386  80 147]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.53      0.83      0.65       999
     warning       0.66      0.45      0.54       801
     seeding       0.50      0.24      0.32       613
    accuracy                           0.56      2413

   macro avg       0.56      0.51      0.50      2413
weighted avg       0.57      0.56      0.53      2413



uitnlp/CafeBERT
[11:44:05] task: task-1                                                                                 my_import.py:91
           model_type: simple                                                                           my_import.py:91
           model_name: uitnlp/CafeBERT                                                                  my_import.py:91
           padding_len: 400                                                                             my_import.py:85
           batch_size: 32                                                                               my_import.py:91
           learning_rate: 0.001                                                                         my_import.py:91
           epochs: 10                                                                                   my_import.py:91
           device: cuda                                                                                 my_import.py:91
           saving_path: ./models/task_1/simple_CafeBERT                                                 my_import.py:91
           train_shape: (8444, 28)                                                                      my_import.py:91
           dev_shape: (1207, 28)                                                                        my_import.py:91
           test_shape: (2413, 28)                                                                       my_import.py:91

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.



model_weight_path: ./models/task_1/simple_CafeBERT_11.pth
Loading model weight successfully!

Evaluation on dev set
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:25<00:00,  1.71it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:25<00:00,  1.46it/s]
Evaluation, Loss: 39.6102, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005

Confusion Matrix:
[[519   0   0]
 [381   0   0]
 [307   0   0]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.43      1.00      0.60       519
     warning       0.00      0.00      0.00       381
     seeding       0.00      0.00      0.00       307
    accuracy                           0.43      1207

   macro avg       0.14      0.33      0.20      1207
weighted avg       0.18      0.43      0.26      1207

Evaluation on test set
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:47<00:00,  1.90it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:47<00:00,  1.59it/s]
Evaluation, Loss: 79.2125, Acc: 0.4140, Precision: 0.1380, Recall: 0.3333, F1: 0.1952

Confusion Matrix:
[[999   0   0]
 [801   0   0]
 [613   0   0]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.41      1.00      0.59       999
     warning       0.00      0.00      0.00       801
     seeding       0.00      0.00      0.00       613
    accuracy                           0.41      2413

   macro avg       0.14      0.33      0.20      2413
weighted avg       0.17      0.41      0.24      2413



xlm-roberta-base
[11:45:37] task: task-1                                                                                 my_import.py:91
           model_type: simple                                                                           my_import.py:91
           model_name: xlm-roberta-base                                                                 my_import.py:91
           padding_len: 500                                                                             my_import.py:85
           batch_size: 32                                                                               my_import.py:91
           learning_rate: 0.001                                                                         my_import.py:91
           epochs: 10                                                                                   my_import.py:91
           device: cuda                                                                                 my_import.py:91
           saving_path: ./models/task_1/simple_xlm-roberta-base                                         my_import.py:91
           train_shape: (8444, 28)                                                                      my_import.py:91
           dev_shape: (1207, 28)                                                                        my_import.py:91
           test_shape: (2413, 28)                                                                       my_import.py:91


model_weight_path: ./models/task_1/simple_xlm-roberta-base_5.pth
Loading model weight successfully!

Evaluation on dev set
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:12<00:00,  4.00it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:12<00:00,  2.97it/s]
Evaluation, Loss: 40.8679, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005

Confusion Matrix:
[[519   0   0]
 [381   0   0]
 [307   0   0]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.43      1.00      0.60       519
     warning       0.00      0.00      0.00       381
     seeding       0.00      0.00      0.00       307
    accuracy                           0.43      1207

   macro avg       0.14      0.33      0.20      1207
weighted avg       0.18      0.43      0.26      1207

Evaluation on test set
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:20<00:00,  4.42it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:20<00:00,  3.73it/s]
Evaluation, Loss: 81.9716, Acc: 0.4140, Precision: 0.1380, Recall: 0.3333, F1: 0.1952

Confusion Matrix:
[[999   0   0]
 [801   0   0]
 [613   0   0]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.41      1.00      0.59       999
     warning       0.00      0.00      0.00       801
     seeding       0.00      0.00      0.00       613
    accuracy                           0.41      2413

   macro avg       0.14      0.33      0.20      2413
weighted avg       0.17      0.41      0.24      2413



bert-base-multilingual-cased
[11:46:25] task: task-1                                                                                 my_import.py:91
           model_type: simple                                                                           my_import.py:91
           model_name: bert-base-multilingual-cased                                                     my_import.py:91
           padding_len: 500                                                                             my_import.py:85
           batch_size: 32                                                                               my_import.py:91
           learning_rate: 0.001                                                                         my_import.py:91
           epochs: 10                                                                                   my_import.py:91
           device: cuda                                                                                 my_import.py:91
           saving_path: ./models/task_1/simple_bert-base-multilingual-cased                             my_import.py:91
           train_shape: (8444, 28)                                                                      my_import.py:91
           dev_shape: (1207, 28)                                                                        my_import.py:91
           test_shape: (2413, 28)                                                                       my_import.py:91


model_weight_path: ./models/task_1/simple_bert-base-multilingual-cased_6.pth
Loading model weight successfully!

Evaluation on dev set
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:12<00:00,  3.93it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:12<00:00,  3.07it/s]
Evaluation, Loss: 40.0212, Acc: 0.4582, Precision: 0.2973, Recall: 0.3780, F1: 0.3097

Confusion Matrix:
[[455  64   0]
 [283  98   0]
 [239  68   0]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.47      0.88      0.61       519
     warning       0.43      0.26      0.32       381
     seeding       0.00      0.00      0.00       307
    accuracy                           0.46      1207

   macro avg       0.30      0.38      0.31      1207
weighted avg       0.33      0.46      0.36      1207

Evaluation on test set
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:20<00:00,  4.38it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:20<00:00,  3.67it/s]
Evaluation, Loss: 79.3149, Acc: 0.4513, Precision: 0.3001, Recall: 0.3809, F1: 0.3101

Confusion Matrix:
[[876 123   0]
 [588 213   0]
 [474 139   0]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.45      0.88      0.60       999
     warning       0.45      0.27      0.33       801
     seeding       0.00      0.00      0.00       613
    accuracy                           0.45      2413

   macro avg       0.30      0.38      0.31      2413
weighted avg       0.34      0.45      0.36      2413



distilbert-base-multilingual-cased
[11:47:09] task: task-1                                                                                 my_import.py:91
           model_type: simple                                                                           my_import.py:91
           model_name: distilbert-base-multilingual-cased                                               my_import.py:91
           padding_len: 500                                                                             my_import.py:85
           batch_size: 32                                                                               my_import.py:91
           learning_rate: 0.001                                                                         my_import.py:91
           epochs: 10                                                                                   my_import.py:91
           device: cuda                                                                                 my_import.py:91
           saving_path: ./models/task_1/simple_distilbert-base-multilingual-cased                       my_import.py:91
           train_shape: (8444, 28)                                                                      my_import.py:91
           dev_shape: (1207, 28)                                                                        my_import.py:91
           test_shape: (2413, 28)                                                                       my_import.py:91


model_weight_path: ./models/task_1/simple_distilbert-base-multilingual-cased_18.pth
Loading model weight successfully!

Evaluation on dev set
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:07<00:00,  6.99it/s]
Evaluation, Batch 38/38: 100%|██████████| 38/38 [00:07<00:00,  4.76it/s]
Evaluation, Loss: 35.6020, Acc: 0.5609, Precision: 0.5218, Recall: 0.4885, F1: 0.4433

Confusion Matrix:
[[456  51  12]
 [164 210   7]
 [244  52  11]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.53      0.88      0.66       519
     warning       0.67      0.55      0.61       381
     seeding       0.37      0.04      0.07       307
    accuracy                           0.56      1207

   macro avg       0.52      0.49      0.44      1207
weighted avg       0.53      0.56      0.49      1207

Evaluation on test set
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Batch 76/76: 100%|██████████| 76/76 [00:12<00:00,  6.17it/s]
Evaluation, Loss: 71.0916, Acc: 0.5479, Precision: 0.5137, Recall: 0.4798, F1: 0.4328

Confusion Matrix:
[[891  91  17]
 [370 406  25]
 [461 127  25]]
Classification Report:
              precision    recall  f1-score   support
       clean       0.52      0.89      0.65       999
     warning       0.65      0.51      0.57       801
     seeding       0.37      0.04      0.07       613
    accuracy                           0.55      2413

   macro avg       0.51      0.48      0.43      2413
weighted avg       0.52      0.55      0.48      2413



All commands completed!

