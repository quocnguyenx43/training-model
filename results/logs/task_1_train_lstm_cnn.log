======= Training LSTM =======

lstm + vinai/phobert-base
[12:09:30] task: task-1                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: vinai/phobert-base                                                              my_import.py:127
           padding_len: 200                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/lstm_phobert-base                                              my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 280.5644, Acc: 0.4352, Precision: 0.3291, Recall: 0.3375, F1: 0.2190
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.2746, Acc: 0.4300, Precision: 0.2545, Recall: 0.3338, F1: 0.2026
Saved the best model to path: ./models/task_1/lstm_phobert-base_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 274.6283, Acc: 0.4491, Precision: 0.3841, Recall: 0.3847, F1: 0.3105
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.0055, Acc: 0.4548, Precision: 0.2867, Recall: 0.4072, F1: 0.3323
Saved the best model to path: ./models/task_1/lstm_phobert-base_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 272.3548, Acc: 0.4543, Precision: 0.4162, Recall: 0.4029, F1: 0.3308
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.6725, Acc: 0.4507, Precision: 0.3231, Recall: 0.3725, F1: 0.2870
Saved the best model to path: ./models/task_1/lstm_phobert-base_2.pth


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 271.6479, Acc: 0.4603, Precision: 0.4486, Recall: 0.4066, F1: 0.3428
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.1862, Acc: 0.4722, Precision: 0.5183, Recall: 0.4086, F1: 0.3639


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 268.5603, Acc: 0.4775, Precision: 0.4681, Recall: 0.4254, F1: 0.3913
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.5677, Acc: 0.5021, Precision: 0.5247, Recall: 0.4592, F1: 0.4424
Saved the best model to path: ./models/task_1/lstm_phobert-base_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 262.5600, Acc: 0.5073, Precision: 0.4934, Recall: 0.4573, F1: 0.4543
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.2423, Acc: 0.4946, Precision: 0.5316, Recall: 0.4491, F1: 0.4309


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 259.1693, Acc: 0.5211, Precision: 0.5166, Recall: 0.4670, F1: 0.4629
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.6541, Acc: 0.5369, Precision: 0.5664, Recall: 0.4778, F1: 0.4710
Saved the best model to path: ./models/task_1/lstm_phobert-base_6.pth


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 255.0952, Acc: 0.5281, Precision: 0.5260, Recall: 0.4779, F1: 0.4761
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.2147, Acc: 0.5344, Precision: 0.5573, Recall: 0.4775, F1: 0.4686


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 253.9210, Acc: 0.5340, Precision: 0.5302, Recall: 0.4853, F1: 0.4849
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.7780, Acc: 0.5493, Precision: 0.5789, Recall: 0.4886, F1: 0.4815


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 251.6833, Acc: 0.5416, Precision: 0.5383, Recall: 0.4951, F1: 0.4964
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.4368, Acc: 0.5220, Precision: 0.5272, Recall: 0.4877, F1: 0.4846


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 251.6978, Acc: 0.5465, Precision: 0.5469, Recall: 0.4993, F1: 0.5011
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.2742, Acc: 0.5551, Precision: 0.5837, Recall: 0.5020, F1: 0.4900
Saved the best model to path: ./models/task_1/lstm_phobert-base_10.pth


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 251.0861, Acc: 0.5478, Precision: 0.5484, Recall: 0.4976, F1: 0.4990
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.3725, Acc: 0.5427, Precision: 0.5834, Recall: 0.4804, F1: 0.4707


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 250.0445, Acc: 0.5484, Precision: 0.5480, Recall: 0.4984, F1: 0.4999
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.3870, Acc: 0.5443, Precision: 0.5750, Recall: 0.4839, F1: 0.4763


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 249.0657, Acc: 0.5522, Precision: 0.5502, Recall: 0.5041, F1: 0.5060
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.0249, Acc: 0.5559, Precision: 0.5897, Recall: 0.4993, F1: 0.4970
Saved the best model to path: ./models/task_1/lstm_phobert-base_13.pth


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 247.9778, Acc: 0.5573, Precision: 0.5604, Recall: 0.5093, F1: 0.5117
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.2982, Acc: 0.5460, Precision: 0.5449, Recall: 0.5125, F1: 0.5174


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 246.8611, Acc: 0.5586, Precision: 0.5622, Recall: 0.5117, F1: 0.5153
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.5187, Acc: 0.5626, Precision: 0.5640, Recall: 0.5241, F1: 0.5289
Saved the best model to path: ./models/task_1/lstm_phobert-base_15.pth


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 247.1389, Acc: 0.5567, Precision: 0.5643, Recall: 0.5083, F1: 0.5113
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.1297, Acc: 0.5460, Precision: 0.5874, Recall: 0.4818, F1: 0.4697


Epoch 18/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 18/20, Loss: 246.8939, Acc: 0.5554, Precision: 0.5561, Recall: 0.5098, F1: 0.5129
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.8886, Acc: 0.5518, Precision: 0.5870, Recall: 0.4999, F1: 0.4994


Epoch 19/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 19/20, Loss: 246.3016, Acc: 0.5531, Precision: 0.5531, Recall: 0.5053, F1: 0.5079
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.6788, Acc: 0.5518, Precision: 0.5585, Recall: 0.5064, F1: 0.5080


Epoch 20/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 20/20, Loss: 245.8705, Acc: 0.5615, Precision: 0.5633, Recall: 0.5138, F1: 0.5168
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.6923, Acc: 0.5642, Precision: 0.5884, Recall: 0.5106, F1: 0.5104

lstm + uitnlp/visobert
[12:21:30] task: task-1                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: uitnlp/visobert                                                                 my_import.py:127
           padding_len: 400                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/lstm_visobert                                                  my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/visobert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 279.4193, Acc: 0.4480, Precision: 0.3611, Recall: 0.3538, F1: 0.2684
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.9366, Acc: 0.4656, Precision: 0.3438, Recall: 0.3742, F1: 0.2861
Saved the best model to path: ./models/task_1/lstm_visobert_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 269.2401, Acc: 0.4781, Precision: 0.4641, Recall: 0.4055, F1: 0.3726
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.7796, Acc: 0.4838, Precision: 0.4861, Recall: 0.4471, F1: 0.4303
Saved the best model to path: ./models/task_1/lstm_visobert_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 263.7410, Acc: 0.5012, Precision: 0.4966, Recall: 0.4448, F1: 0.4322
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.0500, Acc: 0.5327, Precision: 0.5411, Recall: 0.4953, F1: 0.4948
Saved the best model to path: ./models/task_1/lstm_visobert_2.pth


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 256.3343, Acc: 0.5300, Precision: 0.5185, Recall: 0.4841, F1: 0.4845
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.8994, Acc: 0.5336, Precision: 0.5745, Recall: 0.4819, F1: 0.4725
Saved the best model to path: ./models/task_1/lstm_visobert_3.pth


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 251.7206, Acc: 0.5514, Precision: 0.5461, Recall: 0.5057, F1: 0.5071
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3801, Acc: 0.5783, Precision: 0.5706, Recall: 0.5401, F1: 0.5437
Saved the best model to path: ./models/task_1/lstm_visobert_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 250.0120, Acc: 0.5486, Precision: 0.5392, Recall: 0.5091, F1: 0.5111
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.5867, Acc: 0.5642, Precision: 0.5829, Recall: 0.5138, F1: 0.5147


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 248.9368, Acc: 0.5625, Precision: 0.5580, Recall: 0.5193, F1: 0.5217
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.1590, Acc: 0.5816, Precision: 0.6025, Recall: 0.5523, F1: 0.5552
Saved the best model to path: ./models/task_1/lstm_visobert_6.pth


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 247.0016, Acc: 0.5612, Precision: 0.5565, Recall: 0.5190, F1: 0.5221
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.2092, Acc: 0.5800, Precision: 0.5693, Recall: 0.5359, F1: 0.5346


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 245.2077, Acc: 0.5675, Precision: 0.5621, Recall: 0.5276, F1: 0.5309
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3053, Acc: 0.5584, Precision: 0.5647, Recall: 0.5561, F1: 0.5536


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 244.5136, Acc: 0.5653, Precision: 0.5589, Recall: 0.5228, F1: 0.5260
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.0301, Acc: 0.5849, Precision: 0.5873, Recall: 0.5483, F1: 0.5534
Saved the best model to path: ./models/task_1/lstm_visobert_9.pth


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 243.9137, Acc: 0.5677, Precision: 0.5629, Recall: 0.5277, F1: 0.5319
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.1780, Acc: 0.5824, Precision: 0.6003, Recall: 0.5334, F1: 0.5373


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 244.9922, Acc: 0.5683, Precision: 0.5671, Recall: 0.5229, F1: 0.5260
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.0839, Acc: 0.5857, Precision: 0.5999, Recall: 0.5491, F1: 0.5554


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 242.0159, Acc: 0.5767, Precision: 0.5741, Recall: 0.5337, F1: 0.5378
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.6306, Acc: 0.5915, Precision: 0.6087, Recall: 0.5416, F1: 0.5449
Saved the best model to path: ./models/task_1/lstm_visobert_12.pth


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 241.9254, Acc: 0.5757, Precision: 0.5754, Recall: 0.5327, F1: 0.5367
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.5066, Acc: 0.5982, Precision: 0.5979, Recall: 0.5723, F1: 0.5783
Saved the best model to path: ./models/task_1/lstm_visobert_13.pth


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 242.6037, Acc: 0.5772, Precision: 0.5727, Recall: 0.5354, F1: 0.5398
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.6791, Acc: 0.5824, Precision: 0.6027, Recall: 0.5249, F1: 0.5228


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 239.4364, Acc: 0.5756, Precision: 0.5715, Recall: 0.5335, F1: 0.5377
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.2405, Acc: 0.5973, Precision: 0.6031, Recall: 0.5583, F1: 0.5646
Saved the best model to path: ./models/task_1/lstm_visobert_15.pth


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 241.1888, Acc: 0.5748, Precision: 0.5731, Recall: 0.5321, F1: 0.5364
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.4115, Acc: 0.5990, Precision: 0.6109, Recall: 0.5603, F1: 0.5669


Epoch 18/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 18/20, Loss: 240.8337, Acc: 0.5795, Precision: 0.5717, Recall: 0.5355, F1: 0.5394
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.8205, Acc: 0.5899, Precision: 0.6149, Recall: 0.5384, F1: 0.5423


Epoch 19/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 19/20, Loss: 238.0424, Acc: 0.5816, Precision: 0.5828, Recall: 0.5405, F1: 0.5454
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3524, Acc: 0.5659, Precision: 0.6022, Recall: 0.5079, F1: 0.5064


Epoch 20/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 20/20, Loss: 239.3189, Acc: 0.5796, Precision: 0.5785, Recall: 0.5362, F1: 0.5407
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3194, Acc: 0.5717, Precision: 0.5867, Recall: 0.5232, F1: 0.5257

lstm + uitnlp/CafeBERT
[12:45:30] task: task-1                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: uitnlp/CafeBERT                                                                 my_import.py:127
           padding_len: 300                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/lstm_CafeBERT                                                  my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 283.2139, Acc: 0.4333, Precision: 0.2280, Recall: 0.3322, F1: 0.2035
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8830, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/lstm_CafeBERT_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 282.4547, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8785, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/lstm_CafeBERT_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 282.6655, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8829, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 282.5981, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9348, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 282.5952, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9185, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 282.5521, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8865, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 281.9223, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5700, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/lstm_CafeBERT_6.pth


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 278.4748, Acc: 0.4357, Precision: 0.3668, Recall: 0.3446, F1: 0.2464
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5884, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 275.8929, Acc: 0.4450, Precision: 0.3850, Recall: 0.3620, F1: 0.3049
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.1017, Acc: 0.4557, Precision: 0.3081, Recall: 0.3681, F1: 0.2863
Saved the best model to path: ./models/task_1/lstm_CafeBERT_8.pth


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 274.9972, Acc: 0.4495, Precision: 0.3848, Recall: 0.3667, F1: 0.3130
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.9464, Acc: 0.4524, Precision: 0.3678, Recall: 0.3579, F1: 0.2528
Saved the best model to path: ./models/task_1/lstm_CafeBERT_9.pth


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 272.7262, Acc: 0.4658, Precision: 0.4202, Recall: 0.3818, F1: 0.3227
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.2311, Acc: 0.4847, Precision: 0.3219, Recall: 0.4060, F1: 0.3414
Saved the best model to path: ./models/task_1/lstm_CafeBERT_10.pth


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 271.0244, Acc: 0.4670, Precision: 0.4134, Recall: 0.3848, F1: 0.3332
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.3998, Acc: 0.4606, Precision: 0.3035, Recall: 0.4078, F1: 0.3479


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 270.5515, Acc: 0.4768, Precision: 0.4415, Recall: 0.3957, F1: 0.3480
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.1660, Acc: 0.4565, Precision: 0.4064, Recall: 0.3755, F1: 0.3091


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 268.4196, Acc: 0.4834, Precision: 0.4521, Recall: 0.4070, F1: 0.3708
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.0416, Acc: 0.4938, Precision: 0.4276, Recall: 0.4192, F1: 0.3686
Saved the best model to path: ./models/task_1/lstm_CafeBERT_13.pth


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 267.0223, Acc: 0.4949, Precision: 0.4559, Recall: 0.4200, F1: 0.3868
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.6931, Acc: 0.5046, Precision: 0.3388, Recall: 0.4388, F1: 0.3785
Saved the best model to path: ./models/task_1/lstm_CafeBERT_14.pth


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 265.5012, Acc: 0.4959, Precision: 0.4536, Recall: 0.4182, F1: 0.3796
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.7730, Acc: 0.4772, Precision: 0.4999, Recall: 0.3913, F1: 0.3204


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 265.1808, Acc: 0.4969, Precision: 0.4649, Recall: 0.4206, F1: 0.3842
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.9662, Acc: 0.5004, Precision: 0.4688, Recall: 0.4276, F1: 0.3933
Saved the best model to path: ./models/task_1/lstm_CafeBERT_16.pth


Epoch 18/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 18/20, Loss: 262.2584, Acc: 0.5066, Precision: 0.4785, Recall: 0.4352, F1: 0.4135
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.3207, Acc: 0.4772, Precision: 0.5149, Recall: 0.3875, F1: 0.3127


Epoch 19/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 19/20, Loss: 261.7184, Acc: 0.5104, Precision: 0.4734, Recall: 0.4366, F1: 0.4109
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.2023, Acc: 0.4747, Precision: 0.5043, Recall: 0.3908, F1: 0.3292


Epoch 20/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 20/20, Loss: 261.4686, Acc: 0.5180, Precision: 0.4887, Recall: 0.4415, F1: 0.4120
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.4139, Acc: 0.5253, Precision: 0.5204, Recall: 0.4546, F1: 0.4309
Saved the best model to path: ./models/task_1/lstm_CafeBERT_19.pth

lstm + xlm-roberta-base
[13:35:42] task: task-1                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: xlm-roberta-base                                                                my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/lstm_xlm-roberta-base                                          my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 283.3616, Acc: 0.4346, Precision: 0.2548, Recall: 0.3337, F1: 0.2074
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9404, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/lstm_xlm-roberta-base_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 282.7553, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8815, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/lstm_xlm-roberta-base_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 282.7063, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9349, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 282.6876, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9348, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 282.5755, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9746, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 282.4877, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9043, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 282.4492, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8935, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005

Early stopping triggered!

lstm + bert-base-multilingual-cased
[13:46:14] task: task-1                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: bert-base-multilingual-cased                                                    my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/lstm_bert-base-multilingual-cased                              my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 281.7126, Acc: 0.4331, Precision: 0.3365, Recall: 0.3338, F1: 0.2131
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.6547, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/lstm_bert-base-multilingual-cased_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 279.8657, Acc: 0.4347, Precision: 0.3879, Recall: 0.3392, F1: 0.2395
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.1881, Acc: 0.4325, Precision: 0.3107, Recall: 0.3362, F1: 0.2079


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 278.5453, Acc: 0.4456, Precision: 0.4136, Recall: 0.3550, F1: 0.2793
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.7922, Acc: 0.4085, Precision: 0.2713, Recall: 0.3620, F1: 0.3088


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 277.3005, Acc: 0.4488, Precision: 0.3869, Recall: 0.3605, F1: 0.2924
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.2618, Acc: 0.4582, Precision: 0.3212, Recall: 0.3670, F1: 0.2765
Saved the best model to path: ./models/task_1/lstm_bert-base-multilingual-cased_3.pth


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 277.0466, Acc: 0.4527, Precision: 0.4380, Recall: 0.3661, F1: 0.3005
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.9326, Acc: 0.4598, Precision: 0.2948, Recall: 0.3809, F1: 0.3140
Saved the best model to path: ./models/task_1/lstm_bert-base-multilingual-cased_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 275.4043, Acc: 0.4651, Precision: 0.3924, Recall: 0.3766, F1: 0.3111
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.4046, Acc: 0.4573, Precision: 0.5498, Recall: 0.3655, F1: 0.2713


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 275.2166, Acc: 0.4639, Precision: 0.4453, Recall: 0.3775, F1: 0.3188
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.0855, Acc: 0.4466, Precision: 0.3901, Recall: 0.3843, F1: 0.3449


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 274.7535, Acc: 0.4628, Precision: 0.4172, Recall: 0.3741, F1: 0.3105
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.0389, Acc: 0.4606, Precision: 0.3974, Recall: 0.3733, F1: 0.2963


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 274.2548, Acc: 0.4683, Precision: 0.4178, Recall: 0.3798, F1: 0.3190
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.1851, Acc: 0.4640, Precision: 0.5163, Recall: 0.3743, F1: 0.2917


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 274.1776, Acc: 0.4690, Precision: 0.4618, Recall: 0.3786, F1: 0.3127
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.0880, Acc: 0.4615, Precision: 0.4414, Recall: 0.3805, F1: 0.3215

Early stopping triggered!

lstm + distilbert-base-multilingual-cased
[14:01:16] task: task-1                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: distilbert-base-multilingual-cased                                              my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/lstm_distilbert-base-multilingual-cased                        my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 279.9382, Acc: 0.4370, Precision: 0.3755, Recall: 0.3429, F1: 0.2519
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.1343, Acc: 0.4656, Precision: 0.3037, Recall: 0.3872, F1: 0.3218
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 271.2446, Acc: 0.4719, Precision: 0.4345, Recall: 0.3861, F1: 0.3325
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.8510, Acc: 0.4631, Precision: 0.5449, Recall: 0.3811, F1: 0.3112
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 267.3369, Acc: 0.4793, Precision: 0.4594, Recall: 0.4085, F1: 0.3827
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.9773, Acc: 0.4921, Precision: 0.5061, Recall: 0.4117, F1: 0.3537
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_2.pth


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 263.9914, Acc: 0.4937, Precision: 0.4676, Recall: 0.4226, F1: 0.4009
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.4501, Acc: 0.5120, Precision: 0.5052, Recall: 0.4591, F1: 0.4540
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_3.pth


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 255.5555, Acc: 0.5294, Precision: 0.5152, Recall: 0.4731, F1: 0.4693
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.5568, Acc: 0.5377, Precision: 0.5389, Recall: 0.4849, F1: 0.4832
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 251.4747, Acc: 0.5391, Precision: 0.5299, Recall: 0.4845, F1: 0.4826
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.0930, Acc: 0.5286, Precision: 0.5325, Recall: 0.4934, F1: 0.4990
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_5.pth


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 250.5716, Acc: 0.5482, Precision: 0.5416, Recall: 0.4997, F1: 0.5011
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.5379, Acc: 0.5352, Precision: 0.4957, Recall: 0.4845, F1: 0.4548


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 248.1920, Acc: 0.5564, Precision: 0.5490, Recall: 0.5045, F1: 0.5046
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.0733, Acc: 0.5294, Precision: 0.5317, Recall: 0.4571, F1: 0.4334
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_7.pth


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 246.3808, Acc: 0.5616, Precision: 0.5554, Recall: 0.5126, F1: 0.5137
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3361, Acc: 0.5584, Precision: 0.5519, Recall: 0.5087, F1: 0.5087
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_8.pth


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 243.4543, Acc: 0.5732, Precision: 0.5727, Recall: 0.5264, F1: 0.5289
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.4123, Acc: 0.5601, Precision: 0.5666, Recall: 0.5045, F1: 0.5020


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 242.6329, Acc: 0.5818, Precision: 0.5816, Recall: 0.5409, F1: 0.5438
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.4661, Acc: 0.5617, Precision: 0.5765, Recall: 0.5294, F1: 0.5327


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 241.2600, Acc: 0.5785, Precision: 0.5808, Recall: 0.5367, F1: 0.5404
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.0104, Acc: 0.5634, Precision: 0.5849, Recall: 0.5167, F1: 0.5203


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 240.0981, Acc: 0.5862, Precision: 0.5851, Recall: 0.5419, F1: 0.5460
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.4667, Acc: 0.5750, Precision: 0.5712, Recall: 0.5369, F1: 0.5417
Saved the best model to path: ./models/task_1/lstm_distilbert-base-multilingual-cased_12.pth


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 239.8344, Acc: 0.5836, Precision: 0.5845, Recall: 0.5444, F1: 0.5488
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.8069, Acc: 0.5783, Precision: 0.5943, Recall: 0.5324, F1: 0.5370


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 238.3084, Acc: 0.5873, Precision: 0.5862, Recall: 0.5420, F1: 0.5463
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.7188, Acc: 0.5940, Precision: 0.5932, Recall: 0.5677, F1: 0.5727


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 238.3471, Acc: 0.5855, Precision: 0.5833, Recall: 0.5416, F1: 0.5457
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.6206, Acc: 0.5841, Precision: 0.5765, Recall: 0.5567, F1: 0.5610


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 238.1693, Acc: 0.5899, Precision: 0.5895, Recall: 0.5452, F1: 0.5502
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.7651, Acc: 0.5742, Precision: 0.5900, Recall: 0.5323, F1: 0.5375


Epoch 18/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 18/20, Loss: 235.7030, Acc: 0.5925, Precision: 0.5946, Recall: 0.5485, F1: 0.5536
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.8287, Acc: 0.5949, Precision: 0.5872, Recall: 0.5679, F1: 0.5728

Early stopping triggered!



======= Training CNN =======

cnn + vinai/phobert-base
[18:48:08] task: task-1                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: vinai/phobert-base                                                              my_import.py:127
           padding_len: 200                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/cnn_phobert-base                                               my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 283.5122, Acc: 0.4324, Precision: 0.3723, Recall: 0.3539, F1: 0.3041
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9124, Acc: 0.4557, Precision: 0.3562, Recall: 0.3632, F1: 0.2677
Saved the best model to path: ./models/task_1/cnn_phobert-base_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 272.4318, Acc: 0.4580, Precision: 0.4172, Recall: 0.3814, F1: 0.3397
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.1528, Acc: 0.4797, Precision: 0.3469, Recall: 0.3916, F1: 0.3158
Saved the best model to path: ./models/task_1/cnn_phobert-base_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 268.0041, Acc: 0.4842, Precision: 0.4585, Recall: 0.4185, F1: 0.4011
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.4446, Acc: 0.4863, Precision: 0.5378, Recall: 0.4072, F1: 0.3585
Saved the best model to path: ./models/task_1/cnn_phobert-base_2.pth


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 265.5992, Acc: 0.5006, Precision: 0.4820, Recall: 0.4539, F1: 0.4505
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.0284, Acc: 0.4979, Precision: 0.5554, Recall: 0.4158, F1: 0.3669
Saved the best model to path: ./models/task_1/cnn_phobert-base_3.pth


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 265.1643, Acc: 0.5028, Precision: 0.4876, Recall: 0.4548, F1: 0.4511
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.0099, Acc: 0.5104, Precision: 0.5364, Recall: 0.4410, F1: 0.4164
Saved the best model to path: ./models/task_1/cnn_phobert-base_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 262.3684, Acc: 0.5130, Precision: 0.5011, Recall: 0.4645, F1: 0.4622
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.0573, Acc: 0.5046, Precision: 0.4993, Recall: 0.4629, F1: 0.4478


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 259.2631, Acc: 0.5189, Precision: 0.5154, Recall: 0.4694, F1: 0.4664
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.9781, Acc: 0.5286, Precision: 0.5807, Recall: 0.4670, F1: 0.4539
Saved the best model to path: ./models/task_1/cnn_phobert-base_6.pth


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 259.8498, Acc: 0.5126, Precision: 0.5013, Recall: 0.4629, F1: 0.4606
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.5151, Acc: 0.5302, Precision: 0.5998, Recall: 0.4550, F1: 0.4260


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 260.1075, Acc: 0.5231, Precision: 0.5101, Recall: 0.4690, F1: 0.4660
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.9352, Acc: 0.5360, Precision: 0.5709, Recall: 0.4715, F1: 0.4497
Saved the best model to path: ./models/task_1/cnn_phobert-base_8.pth


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 259.2998, Acc: 0.5251, Precision: 0.5206, Recall: 0.4685, F1: 0.4649
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.2458, Acc: 0.5079, Precision: 0.5971, Recall: 0.4236, F1: 0.3711


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 257.7010, Acc: 0.5314, Precision: 0.5216, Recall: 0.4897, F1: 0.4905
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.0181, Acc: 0.5510, Precision: 0.5744, Recall: 0.4936, F1: 0.4892


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 257.1255, Acc: 0.5319, Precision: 0.5236, Recall: 0.4813, F1: 0.4810
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.3678, Acc: 0.5476, Precision: 0.5499, Recall: 0.4855, F1: 0.4729
Saved the best model to path: ./models/task_1/cnn_phobert-base_11.pth


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 255.7181, Acc: 0.5278, Precision: 0.5157, Recall: 0.4782, F1: 0.4779
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.0340, Acc: 0.5244, Precision: 0.5751, Recall: 0.4534, F1: 0.4308


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 256.0883, Acc: 0.5341, Precision: 0.5291, Recall: 0.4867, F1: 0.4874
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.6329, Acc: 0.5609, Precision: 0.5754, Recall: 0.5042, F1: 0.5000


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 255.8935, Acc: 0.5352, Precision: 0.5284, Recall: 0.4874, F1: 0.4881
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.8678, Acc: 0.5476, Precision: 0.5610, Recall: 0.4898, F1: 0.4840


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 254.7031, Acc: 0.5352, Precision: 0.5327, Recall: 0.4838, F1: 0.4832
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.6483, Acc: 0.5435, Precision: 0.5713, Recall: 0.4916, F1: 0.4874


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 256.1495, Acc: 0.5327, Precision: 0.5299, Recall: 0.4832, F1: 0.4827
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.4857, Acc: 0.5385, Precision: 0.5763, Recall: 0.4651, F1: 0.4370

Early stopping triggered!

cnn + uitnlp/visobert
[19:01:28] task: task-1                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: uitnlp/visobert                                                                 my_import.py:127
           padding_len: 400                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/cnn_visobert                                                   my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/visobert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 284.6641, Acc: 0.4549, Precision: 0.4103, Recall: 0.3930, F1: 0.3752
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.9204, Acc: 0.5228, Precision: 0.5159, Recall: 0.4596, F1: 0.4034
Saved the best model to path: ./models/task_1/cnn_visobert_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 261.2311, Acc: 0.5166, Precision: 0.4979, Recall: 0.4649, F1: 0.4622
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.3255, Acc: 0.5485, Precision: 0.5575, Recall: 0.4984, F1: 0.4971
Saved the best model to path: ./models/task_1/cnn_visobert_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 257.7143, Acc: 0.5283, Precision: 0.5161, Recall: 0.4758, F1: 0.4737
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.0438, Acc: 0.5592, Precision: 0.5693, Recall: 0.5302, F1: 0.5304
Saved the best model to path: ./models/task_1/cnn_visobert_2.pth


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 255.5620, Acc: 0.5342, Precision: 0.5274, Recall: 0.4849, F1: 0.4850
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.3450, Acc: 0.5311, Precision: 0.5892, Recall: 0.4831, F1: 0.4675


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 254.7750, Acc: 0.5413, Precision: 0.5360, Recall: 0.4904, F1: 0.4902
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.0006, Acc: 0.5493, Precision: 0.5627, Recall: 0.4995, F1: 0.4997


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 252.3840, Acc: 0.5508, Precision: 0.5520, Recall: 0.4981, F1: 0.4974
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.5978, Acc: 0.5675, Precision: 0.5744, Recall: 0.5115, F1: 0.4941
Saved the best model to path: ./models/task_1/cnn_visobert_5.pth


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 250.0459, Acc: 0.5512, Precision: 0.5471, Recall: 0.5010, F1: 0.5021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3705, Acc: 0.5684, Precision: 0.5756, Recall: 0.5160, F1: 0.5098
Saved the best model to path: ./models/task_1/cnn_visobert_6.pth


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 250.1596, Acc: 0.5529, Precision: 0.5567, Recall: 0.5019, F1: 0.5035
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.1591, Acc: 0.5501, Precision: 0.5865, Recall: 0.4913, F1: 0.4860


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 250.1994, Acc: 0.5468, Precision: 0.5404, Recall: 0.4983, F1: 0.4986
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.0172, Acc: 0.5775, Precision: 0.5859, Recall: 0.5230, F1: 0.5186
Saved the best model to path: ./models/task_1/cnn_visobert_8.pth


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 249.2809, Acc: 0.5558, Precision: 0.5556, Recall: 0.5065, F1: 0.5083
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3955, Acc: 0.5742, Precision: 0.5997, Recall: 0.5483, F1: 0.5461


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 247.3281, Acc: 0.5622, Precision: 0.5652, Recall: 0.5164, F1: 0.5197
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.9369, Acc: 0.5857, Precision: 0.5894, Recall: 0.5426, F1: 0.5468
Saved the best model to path: ./models/task_1/cnn_visobert_10.pth


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 247.6464, Acc: 0.5673, Precision: 0.5624, Recall: 0.5194, F1: 0.5213
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.5444, Acc: 0.5857, Precision: 0.6115, Recall: 0.5343, F1: 0.5376
Saved the best model to path: ./models/task_1/cnn_visobert_11.pth


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 246.1947, Acc: 0.5622, Precision: 0.5580, Recall: 0.5149, F1: 0.5179
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3568, Acc: 0.5700, Precision: 0.6054, Recall: 0.5202, F1: 0.5226


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 244.1185, Acc: 0.5658, Precision: 0.5648, Recall: 0.5158, F1: 0.5177
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.5105, Acc: 0.5891, Precision: 0.6063, Recall: 0.5649, F1: 0.5677
Saved the best model to path: ./models/task_1/cnn_visobert_13.pth


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 245.3946, Acc: 0.5598, Precision: 0.5583, Recall: 0.5118, F1: 0.5142
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.5343, Acc: 0.5675, Precision: 0.6189, Recall: 0.4987, F1: 0.4854


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 243.4105, Acc: 0.5679, Precision: 0.5689, Recall: 0.5212, F1: 0.5242
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.3004, Acc: 0.5717, Precision: 0.6023, Recall: 0.5104, F1: 0.5062


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 243.8309, Acc: 0.5680, Precision: 0.5704, Recall: 0.5216, F1: 0.5244
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.3874, Acc: 0.5841, Precision: 0.5939, Recall: 0.5341, F1: 0.5361


Epoch 18/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 18/20, Loss: 244.1275, Acc: 0.5622, Precision: 0.5652, Recall: 0.5137, F1: 0.5161
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 35.4792, Acc: 0.5891, Precision: 0.5933, Recall: 0.5589, F1: 0.5648


Epoch 19/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 19/20, Loss: 244.4546, Acc: 0.5702, Precision: 0.5681, Recall: 0.5199, F1: 0.5222
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 34.7601, Acc: 0.5915, Precision: 0.5971, Recall: 0.5463, F1: 0.5498

Early stopping triggered!

cnn + uitnlp/CafeBERT
[19:27:18] task: task-1                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: uitnlp/CafeBERT                                                                 my_import.py:127
           padding_len: 300                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/cnn_CafeBERT                                                   my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 297.2701, Acc: 0.4151, Precision: 0.3463, Recall: 0.3347, F1: 0.2754
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.6712, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_CafeBERT_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 282.0542, Acc: 0.4350, Precision: 0.2561, Recall: 0.3333, F1: 0.2023
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8735, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 282.5146, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8773, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 282.5041, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8933, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 282.3256, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9585, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 282.3114, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8918, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005

Early stopping triggered!

cnn + xlm-roberta-base
[19:44:07] task: task-1                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: xlm-roberta-base                                                                my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/cnn_xlm-roberta-base                                           my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 293.5966, Acc: 0.4099, Precision: 0.3156, Recall: 0.3286, F1: 0.2661
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.1613, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_xlm-roberta-base_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 283.6282, Acc: 0.4353, Precision: 0.2734, Recall: 0.3355, F1: 0.2164
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.4380, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 283.4324, Acc: 0.4350, Precision: 0.2634, Recall: 0.3336, F1: 0.2046
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9507, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_xlm-roberta-base_2.pth


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 282.4137, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.0041, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 282.5466, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9348, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_xlm-roberta-base_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 282.3926, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9143, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_xlm-roberta-base_5.pth


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 282.5051, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8991, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_xlm-roberta-base_6.pth


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 282.4755, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9601, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 282.4464, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9381, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 282.5519, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9387, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 282.5308, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9007, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 282.2778, Acc: 0.4351, Precision: 0.1450, Recall: 0.3333, F1: 0.2021
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.9188, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005

Early stopping triggered!

cnn + bert-base-multilingual-cased
[20:03:52] task: task-1                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: bert-base-multilingual-cased                                                    my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/cnn_bert-base-multilingual-cased                               my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 290.7723, Acc: 0.4204, Precision: 0.3394, Recall: 0.3335, F1: 0.2577
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.6320, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_bert-base-multilingual-cased_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 281.6920, Acc: 0.4315, Precision: 0.3508, Recall: 0.3321, F1: 0.2112
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5847, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_bert-base-multilingual-cased_1.pth


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 280.1479, Acc: 0.4336, Precision: 0.2595, Recall: 0.3328, F1: 0.2062
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.0507, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 279.0540, Acc: 0.4343, Precision: 0.2560, Recall: 0.3331, F1: 0.2048
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.7425, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 279.6988, Acc: 0.4351, Precision: 0.2654, Recall: 0.3343, F1: 0.2091
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5107, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005
Saved the best model to path: ./models/task_1/cnn_bert-base-multilingual-cased_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 279.9430, Acc: 0.4315, Precision: 0.3234, Recall: 0.3329, F1: 0.2142
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.6478, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 278.4222, Acc: 0.4353, Precision: 0.2452, Recall: 0.3340, F1: 0.2042
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.4827, Acc: 0.4300, Precision: 0.1433, Recall: 0.3333, F1: 0.2005


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 278.6459, Acc: 0.4334, Precision: 0.3632, Recall: 0.3367, F1: 0.2229
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5860, Acc: 0.4316, Precision: 0.2867, Recall: 0.3353, F1: 0.2060


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 278.0871, Acc: 0.4384, Precision: 0.3816, Recall: 0.3416, F1: 0.2374
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.1251, Acc: 0.4524, Precision: 0.3106, Recall: 0.3637, F1: 0.2780


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 279.3526, Acc: 0.4350, Precision: 0.2701, Recall: 0.3351, F1: 0.2153
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.4965, Acc: 0.4350, Precision: 0.3495, Recall: 0.3390, F1: 0.2147
Saved the best model to path: ./models/task_1/cnn_bert-base-multilingual-cased_9.pth


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 277.8457, Acc: 0.4437, Precision: 0.2798, Recall: 0.3499, F1: 0.2636
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.3084, Acc: 0.4250, Precision: 0.2770, Recall: 0.3714, F1: 0.3173


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 278.0694, Acc: 0.4439, Precision: 0.4001, Recall: 0.3534, F1: 0.2772
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.2354, Acc: 0.4524, Precision: 0.2870, Recall: 0.3772, F1: 0.3137
Saved the best model to path: ./models/task_1/cnn_bert-base-multilingual-cased_11.pth


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 278.4626, Acc: 0.4378, Precision: 0.3964, Recall: 0.3461, F1: 0.2639
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 41.5810, Acc: 0.4325, Precision: 0.3938, Recall: 0.3360, F1: 0.2061


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 278.1744, Acc: 0.4404, Precision: 0.4105, Recall: 0.3480, F1: 0.2636
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5056, Acc: 0.4350, Precision: 0.3319, Recall: 0.3393, F1: 0.2163


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 277.7765, Acc: 0.4414, Precision: 0.3811, Recall: 0.3461, F1: 0.2527
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.1761, Acc: 0.4474, Precision: 0.3455, Recall: 0.3547, F1: 0.2539
Saved the best model to path: ./models/task_1/cnn_bert-base-multilingual-cased_14.pth


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 277.6372, Acc: 0.4430, Precision: 0.4081, Recall: 0.3522, F1: 0.2749
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.3289, Acc: 0.4424, Precision: 0.3764, Recall: 0.3472, F1: 0.2318


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 276.9113, Acc: 0.4495, Precision: 0.3708, Recall: 0.3597, F1: 0.2877
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5850, Acc: 0.4316, Precision: 0.3659, Recall: 0.3351, F1: 0.2043


Epoch 18/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 18/20, Loss: 277.5382, Acc: 0.4375, Precision: 0.3859, Recall: 0.3491, F1: 0.2764
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.2412, Acc: 0.4499, Precision: 0.2858, Recall: 0.3783, F1: 0.3177


Epoch 19/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 19/20, Loss: 276.0449, Acc: 0.4506, Precision: 0.3655, Recall: 0.3632, F1: 0.2974
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.2737, Acc: 0.4573, Precision: 0.2957, Recall: 0.3817, F1: 0.3186


Epoch 20/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 20/20, Loss: 276.8025, Acc: 0.4526, Precision: 0.5102, Recall: 0.3617, F1: 0.2871
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.2404, Acc: 0.4656, Precision: 0.3213, Recall: 0.3779, F1: 0.2987

Early stopping triggered!

cnn + distilbert-base-multilingual-cased
[20:37:19] task: task-1                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: distilbert-base-multilingual-cased                                              my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_1/cnn_distilbert-base-multilingual-cased                         my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 288.0447, Acc: 0.4292, Precision: 0.3712, Recall: 0.3562, F1: 0.3178
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.5606, Acc: 0.4441, Precision: 0.4291, Recall: 0.3482, F1: 0.2311
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_0.pth


Epoch 2/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 2/20, Loss: 272.6567, Acc: 0.4636, Precision: 0.4248, Recall: 0.3775, F1: 0.3213
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 40.8418, Acc: 0.4118, Precision: 0.2731, Recall: 0.3625, F1: 0.3110


Epoch 3/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 3/20, Loss: 269.5514, Acc: 0.4705, Precision: 0.4538, Recall: 0.3992, F1: 0.3711
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.8077, Acc: 0.4565, Precision: 0.4869, Recall: 0.3627, F1: 0.2628
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_2.pth


Epoch 4/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 4/20, Loss: 268.9781, Acc: 0.4840, Precision: 0.4835, Recall: 0.4260, F1: 0.4015
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.9592, Acc: 0.4623, Precision: 0.5332, Recall: 0.4285, F1: 0.3923
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_3.pth


Epoch 5/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 5/20, Loss: 267.0672, Acc: 0.4845, Precision: 0.4819, Recall: 0.4302, F1: 0.4144
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.5255, Acc: 0.4805, Precision: 0.5326, Recall: 0.4322, F1: 0.4104
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_4.pth


Epoch 6/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 6/20, Loss: 264.9306, Acc: 0.4901, Precision: 0.4871, Recall: 0.4412, F1: 0.4323
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.3797, Acc: 0.4822, Precision: 0.5462, Recall: 0.4519, F1: 0.4311
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_5.pth


Epoch 7/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 7/20, Loss: 261.4575, Acc: 0.5062, Precision: 0.4955, Recall: 0.4613, F1: 0.4604
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 39.1290, Acc: 0.4565, Precision: 0.4342, Recall: 0.3890, F1: 0.3414


Epoch 8/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 8/20, Loss: 265.0055, Acc: 0.4923, Precision: 0.4829, Recall: 0.4358, F1: 0.4275
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.8868, Acc: 0.5037, Precision: 0.5272, Recall: 0.4486, F1: 0.4384
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_7.pth


Epoch 9/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 9/20, Loss: 261.8761, Acc: 0.5032, Precision: 0.4973, Recall: 0.4505, F1: 0.4465
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.9881, Acc: 0.4938, Precision: 0.4738, Recall: 0.4202, F1: 0.3854


Epoch 10/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 10/20, Loss: 261.7132, Acc: 0.5065, Precision: 0.4848, Recall: 0.4367, F1: 0.4178
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.6838, Acc: 0.5128, Precision: 0.5165, Recall: 0.4602, F1: 0.4553
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_9.pth


Epoch 11/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 11/20, Loss: 259.6842, Acc: 0.5130, Precision: 0.4946, Recall: 0.4508, F1: 0.4413
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.5875, Acc: 0.4640, Precision: 0.4336, Recall: 0.4176, F1: 0.4106


Epoch 12/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 12/20, Loss: 258.2997, Acc: 0.5186, Precision: 0.5012, Recall: 0.4622, F1: 0.4579
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.4095, Acc: 0.5070, Precision: 0.4851, Recall: 0.4646, F1: 0.4620
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_11.pth


Epoch 13/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 13/20, Loss: 255.3023, Acc: 0.5279, Precision: 0.5207, Recall: 0.4825, F1: 0.4835
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 38.3889, Acc: 0.5021, Precision: 0.4967, Recall: 0.4380, F1: 0.4209


Epoch 14/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 14/20, Loss: 255.2119, Acc: 0.5342, Precision: 0.5307, Recall: 0.4803, F1: 0.4794
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.4350, Acc: 0.5120, Precision: 0.5288, Recall: 0.4565, F1: 0.4482


Epoch 15/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 15/20, Loss: 254.8400, Acc: 0.5359, Precision: 0.5280, Recall: 0.4842, F1: 0.4839
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.0613, Acc: 0.5360, Precision: 0.5295, Recall: 0.4858, F1: 0.4814
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_14.pth


Epoch 16/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 16/20, Loss: 253.6305, Acc: 0.5464, Precision: 0.5434, Recall: 0.4971, F1: 0.4990
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.7766, Acc: 0.5261, Precision: 0.5170, Recall: 0.4729, F1: 0.4669
Saved the best model to path: ./models/task_1/cnn_distilbert-base-multilingual-cased_15.pth


Epoch 17/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 17/20, Loss: 253.9983, Acc: 0.5404, Precision: 0.5342, Recall: 0.4884, F1: 0.4882
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.2052, Acc: 0.5162, Precision: 0.4988, Recall: 0.4717, F1: 0.4630


Epoch 18/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 18/20, Loss: 252.0116, Acc: 0.5432, Precision: 0.5310, Recall: 0.4947, F1: 0.4957
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.9483, Acc: 0.5302, Precision: 0.5416, Recall: 0.4716, F1: 0.4645


Epoch 19/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 19/20, Loss: 253.0607, Acc: 0.5356, Precision: 0.5224, Recall: 0.4848, F1: 0.4851
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 36.9210, Acc: 0.5460, Precision: 0.5561, Recall: 0.4981, F1: 0.4996


Epoch 20/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 20/20, Loss: 252.9523, Acc: 0.5381, Precision: 0.5266, Recall: 0.4903, F1: 0.4916
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 37.9332, Acc: 0.4780, Precision: 0.4463, Recall: 0.4424, F1: 0.4377