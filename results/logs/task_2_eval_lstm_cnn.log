======== Evaluating LSTM ========

lstm + vinai/phobert-base
[16:56:51] task: task-2                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: vinai/phobert-base                                                              my_import.py:127
           padding_len: 200                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/lstm_phobert-base                                              my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/lstm_phobert-base_18.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 50.1070, 0/1 Loss: 0.8732, Hamming Loss: 0.4236, EMR: 0.1268, Acc: 0.9412, F1: 0.6687, Precision: 0.6401, Recall: 0.7296
Confusion Matrix of title aspect
[[  0   7   2   0]
 [  0 479 367   0]
 [  0 151 198   0]
 [  0   2   1   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.75      0.57      0.65       846
           2       0.35      0.57      0.43       349
           3       0.00      0.00      0.00         3

    accuracy                           0.56      1207
   macro avg       0.27      0.28      0.27      1207
weighted avg       0.63      0.56      0.58      1207

Confusion Matrix of desc aspect
[[  0   2   0   0]
 [  0 364 381   0]
 [  0 126 333   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.74      0.49      0.59       745
           2       0.47      0.73      0.57       459
           3       0.00      0.00      0.00         1

    accuracy                           0.58      1207
   macro avg       0.30      0.30      0.29      1207
weighted avg       0.63      0.58      0.58      1207

Confusion Matrix of company aspect
[[  4   0  42  10]
 [156   2 239 189]
 [ 26   0 290  83]
 [  1   0  50 115]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.02      0.07      0.03        56
           1       1.00      0.00      0.01       586
           2       0.47      0.73      0.57       399
           3       0.29      0.69      0.41       166

    accuracy                           0.34      1207
   macro avg       0.44      0.37      0.25      1207
weighted avg       0.68      0.34      0.25      1207

Confusion Matrix of other aspect
[[  0   0   0   0]
 [ 27 998   0   0]
 [  8 122   0   0]
 [  3  49   0   0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.85      0.97      0.91      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.83      1207
   macro avg       0.21      0.24      0.23      1207
weighted avg       0.72      0.83      0.77      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 99.6399, 0/1 Loss: 0.8512, Hamming Loss: 0.4067, EMR: 0.1488, Acc: 0.9472, F1: 0.6712, Precision: 0.6416, Recall: 0.7323
Confusion Matrix of title aspect
[[   0   17    6    0]
 [   0 1005  681    0]
 [   0  299  401    0]
 [   0    2    2    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        23
           1       0.76      0.60      0.67      1686
           2       0.37      0.57      0.45       700
           3       0.00      0.00      0.00         4

    accuracy                           0.58      2413
   macro avg       0.28      0.29      0.28      2413
weighted avg       0.64      0.58      0.60      2413

Confusion Matrix of desc aspect
[[724 727]
 [250 712]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.74      0.50      0.60      1451
           2       0.49      0.74      0.59       962

    accuracy                           0.60      2413
   macro avg       0.62      0.62      0.60      2413
weighted avg       0.64      0.60      0.60      2413

Confusion Matrix of company aspect
[[ 10   1  55  36]
 [279   8 525 370]
 [ 37   1 617 143]
 [  3   0  78 250]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.03      0.10      0.05       102
           1       0.80      0.01      0.01      1182
           2       0.48      0.77      0.60       798
           3       0.31      0.76      0.44       331

    accuracy                           0.37      2413
   macro avg       0.41      0.41      0.27      2413
weighted avg       0.60      0.37      0.27      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [  52 2000    0    0]
 [  19  249    0    0]
 [   1   89    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      0.97      0.91      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.83      2413
   macro avg       0.21      0.24      0.23      2413
weighted avg       0.73      0.83      0.77      2413

lstm + uitnlp/visobert
[16:57:21] task: task-2                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: uitnlp/visobert                                                                 my_import.py:127
           padding_len: 400                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/lstm_visobert                                                  my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/visobert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

model_weight_path: ./models/task_2/lstm_visobert_14.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 50.4541, 0/1 Loss: 0.9809, Hamming Loss: 0.5244, EMR: 0.0191, Acc: 0.9466, F1: 0.6082, Precision: 0.5373, Recall: 0.7372
Confusion Matrix of title aspect
[[  0   9   0   0]
 [130 716   0   0]
 [ 60 289   0   0]
 [  1   2   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.70      0.85      0.77       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.59      1207
   macro avg       0.18      0.21      0.19      1207
weighted avg       0.49      0.59      0.54      1207

Confusion Matrix of desc aspect
[[  0   1   1   0]
 [  0 299 446   0]
 [  0  82 377   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      0.40      0.53       745
           2       0.46      0.82      0.59       459
           3       0.00      0.00      0.00         1

    accuracy                           0.56      1207
   macro avg       0.31      0.31      0.28      1207
weighted avg       0.66      0.56      0.55      1207

Confusion Matrix of company aspect
[[  0   0   0  56]
 [  0   0   0 586]
 [  0   0   0 399]
 [  0   0   0 166]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.14      1.00      0.24       166

    accuracy                           0.14      1207
   macro avg       0.03      0.25      0.06      1207
weighted avg       0.02      0.14      0.03      1207

Confusion Matrix of other aspect
[[710   0 315]
 [ 74   0  56]
 [ 24   0  28]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.88      0.69      0.77      1025
           2       0.00      0.00      0.00       130
           3       0.07      0.54      0.12        52

    accuracy                           0.61      1207
   macro avg       0.32      0.41      0.30      1207
weighted avg       0.75      0.61      0.66      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 100.4823, 0/1 Loss: 0.9768, Hamming Loss: 0.5116, EMR: 0.0232, Acc: 0.9528, F1: 0.6108, Precision: 0.5400, Recall: 0.7386
Confusion Matrix of title aspect
[[   5   18    0    0]
 [ 230 1456    0    0]
 [ 100  600    0    0]
 [   2    2    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      0.22      0.03        23
           1       0.70      0.86      0.77      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.61      2413
   macro avg       0.18      0.27      0.20      2413
weighted avg       0.49      0.61      0.54      2413

Confusion Matrix of desc aspect
[[627 824]
 [148 814]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.81      0.43      0.56      1451
           2       0.50      0.85      0.63       962

    accuracy                           0.60      2413
   macro avg       0.65      0.64      0.59      2413
weighted avg       0.68      0.60      0.59      2413

Confusion Matrix of company aspect
[[   0    0    0  102]
 [   0    0    0 1182]
 [   0    0    0  798]
 [   0    0    0  331]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.14      1.00      0.24       331

    accuracy                           0.14      2413
   macro avg       0.03      0.25      0.06      2413
weighted avg       0.02      0.14      0.03      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 1434    0  618]
 [   1  142    0  125]
 [   0   43    0   47]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.88      0.70      0.78      2052
           2       0.00      0.00      0.00       268
           3       0.06      0.52      0.11        90

    accuracy                           0.61      2413
   macro avg       0.24      0.31      0.22      2413
weighted avg       0.75      0.61      0.67      2413

lstm + uitnlp/CafeBERT
[16:58:02] task: task-2                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: uitnlp/CafeBERT                                                                 my_import.py:127
           padding_len: 300                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/lstm_CafeBERT                                                  my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

model_weight_path: ./models/task_2/lstm_CafeBERT_17.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 50.6648, 0/1 Loss: 0.9992, Hamming Loss: 0.6959, EMR: 0.0008, Acc: 0.7397, F1: 0.5125, Precision: 0.4909, Recall: 0.5746
Confusion Matrix of title aspect
[[  9   0   0   0]
 [846   0   0   0]
 [349   0   0   0]
 [  3   0   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.01         9
           1       0.00      0.00      0.00       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.01      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.01      0.00      1207

Confusion Matrix of desc aspect
[[  0   0   2   0]
 [  0 195 550   0]
 [  0  73 386   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.73      0.26      0.38       745
           2       0.41      0.84      0.55       459
           3       0.00      0.00      0.00         1

    accuracy                           0.48      1207
   macro avg       0.28      0.28      0.23      1207
weighted avg       0.61      0.48      0.45      1207

Confusion Matrix of company aspect
[[  0   0  26  30]
 [  0   0 272 314]
 [  0   0 248 151]
 [  0   0  44 122]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.42      0.62      0.50       399
           3       0.20      0.73      0.31       166

    accuracy                           0.31      1207
   macro avg       0.15      0.34      0.20      1207
weighted avg       0.17      0.31      0.21      1207

Confusion Matrix of other aspect
[[490   0 535]
 [ 77   0  53]
 [ 34   0  18]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.82      0.48      0.60      1025
           2       0.00      0.00      0.00       130
           3       0.03      0.35      0.05        52

    accuracy                           0.42      1207
   macro avg       0.28      0.27      0.22      1207
weighted avg       0.69      0.42      0.51      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 100.9625, 0/1 Loss: 0.9996, Hamming Loss: 0.6923, EMR: 0.0004, Acc: 0.7415, F1: 0.5101, Precision: 0.4866, Recall: 0.5741
Confusion Matrix of title aspect
[[  23    0    0    0]
 [1686    0    0    0]
 [ 700    0    0    0]
 [   4    0    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.02        23
           1       0.00      0.00      0.00      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.01      2413
   macro avg       0.00      0.25      0.00      2413
weighted avg       0.00      0.01      0.00      2413

Confusion Matrix of desc aspect
[[ 363 1088]
 [ 137  825]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.73      0.25      0.37      1451
           2       0.43      0.86      0.57       962

    accuracy                           0.49      2413
   macro avg       0.58      0.55      0.47      2413
weighted avg       0.61      0.49      0.45      2413

Confusion Matrix of company aspect
[[  0   0  53  49]
 [  0   0 525 657]
 [  0   0 499 299]
 [  0   0  86 245]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.43      0.63      0.51       798
           3       0.20      0.74      0.31       331

    accuracy                           0.31      2413
   macro avg       0.16      0.34      0.20      2413
weighted avg       0.17      0.31      0.21      2413

Confusion Matrix of other aspect
[[   0    2    0    1]
 [   0  976    0 1076]
 [   0  138    0  130]
 [   0   51    0   39]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.84      0.48      0.61      2052
           2       0.00      0.00      0.00       268
           3       0.03      0.43      0.06        90

    accuracy                           0.42      2413
   macro avg       0.22      0.23      0.17      2413
weighted avg       0.71      0.42      0.52      2413

lstm + xlm-roberta-base
[16:59:15] task: task-2                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: xlm-roberta-base                                                                my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/lstm_xlm-roberta-base                                          my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/lstm_xlm-roberta-base_11.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 51.5465, 0/1 Loss: 0.9843, Hamming Loss: 0.4830, EMR: 0.0157, Acc: 0.9861, F1: 0.6413, Precision: 0.5635, Recall: 0.7683
Confusion Matrix of title aspect
[[  0   9   0   0]
 [  0 846   0   0]
 [  0 349   0   0]
 [  0   3   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.70      1.00      0.82       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.70      1207
   macro avg       0.18      0.25      0.21      1207
weighted avg       0.49      0.70      0.58      1207

Confusion Matrix of desc aspect
[[  0   0   2   0]
 [  0   0 745   0]
 [  0   0 459   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.38      1.00      0.55       459
           3       0.00      0.00      0.00         1

    accuracy                           0.38      1207
   macro avg       0.10      0.25      0.14      1207
weighted avg       0.14      0.38      0.21      1207

Confusion Matrix of company aspect
[[  0   0   0  56]
 [  0   0   0 586]
 [  0   0   0 399]
 [  0   0   0 166]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.14      1.00      0.24       166

    accuracy                           0.14      1207
   macro avg       0.03      0.25      0.06      1207
weighted avg       0.02      0.14      0.03      1207

Confusion Matrix of other aspect
[[1025    0    0]
 [ 130    0    0]
 [  52    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.85      1.00      0.92      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.85      1207
   macro avg       0.28      0.33      0.31      1207
weighted avg       0.72      0.85      0.78      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 102.9555, 0/1 Loss: 0.9814, Hamming Loss: 0.4788, EMR: 0.0186, Acc: 0.9867, F1: 0.6412, Precision: 0.5639, Recall: 0.7668
Confusion Matrix of title aspect
[[   0   23    0    0]
 [   0 1686    0    0]
 [   0  700    0    0]
 [   0    4    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        23
           1       0.70      1.00      0.82      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.70      2413
   macro avg       0.17      0.25      0.21      2413
weighted avg       0.49      0.70      0.57      2413

Confusion Matrix of desc aspect
[[   0 1451]
 [   0  962]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.00      0.00      0.00      1451
           2       0.40      1.00      0.57       962

    accuracy                           0.40      2413
   macro avg       0.20      0.50      0.29      2413
weighted avg       0.16      0.40      0.23      2413

Confusion Matrix of company aspect
[[   0    0    0  102]
 [   0    0    0 1182]
 [   0    0    0  798]
 [   0    0    0  331]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.14      1.00      0.24       331

    accuracy                           0.14      2413
   macro avg       0.03      0.25      0.06      2413
weighted avg       0.02      0.14      0.03      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 2052    0    0]
 [   0  268    0    0]
 [   0   90    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      1.00      0.92      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.85      2413
   macro avg       0.21      0.25      0.23      2413
weighted avg       0.72      0.85      0.78      2413

lstm + bert-base-multilingual-cased
[16:59:58] task: task-2                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: bert-base-multilingual-cased                                                    my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/lstm_bert-base-multilingual-cased                              my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/lstm_bert-base-multilingual-cased_9.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 51.3939, 0/1 Loss: 1.0000, Hamming Loss: 0.6564, EMR: 0.0000, Acc: 0.7397, F1: 0.5227, Precision: 0.4920, Recall: 0.5746
Confusion Matrix of title aspect
[[  9   0   0   0]
 [846   0   0   0]
 [349   0   0   0]
 [  3   0   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.01         9
           1       0.00      0.00      0.00       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.01      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.01      0.00      1207

Confusion Matrix of desc aspect
[[  0   0   2   0]
 [  0   0 745   0]
 [  0   0 459   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.38      1.00      0.55       459
           3       0.00      0.00      0.00         1

    accuracy                           0.38      1207
   macro avg       0.10      0.25      0.14      1207
weighted avg       0.14      0.38      0.21      1207

Confusion Matrix of company aspect
[[  0   0   0  56]
 [  0   0   0 586]
 [  0   0   0 399]
 [  0   0   0 166]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.14      1.00      0.24       166

    accuracy                           0.14      1207
   macro avg       0.03      0.25      0.06      1207
weighted avg       0.02      0.14      0.03      1207

Confusion Matrix of other aspect
[[1025    0    0]
 [ 130    0    0]
 [  52    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.85      1.00      0.92      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.85      1207
   macro avg       0.28      0.33      0.31      1207
weighted avg       0.72      0.85      0.78      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 102.5815, 0/1 Loss: 0.9992, Hamming Loss: 0.6511, EMR: 0.0008, Acc: 0.7415, F1: 0.5231, Precision: 0.4927, Recall: 0.5741
Confusion Matrix of title aspect
[[  23    0    0    0]
 [1686    0    0    0]
 [ 700    0    0    0]
 [   4    0    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.02        23
           1       0.00      0.00      0.00      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.01      2413
   macro avg       0.00      0.25      0.00      2413
weighted avg       0.00      0.01      0.00      2413

Confusion Matrix of desc aspect
[[   0 1451]
 [   0  962]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.00      0.00      0.00      1451
           2       0.40      1.00      0.57       962

    accuracy                           0.40      2413
   macro avg       0.20      0.50      0.29      2413
weighted avg       0.16      0.40      0.23      2413

Confusion Matrix of company aspect
[[   0    0    0  102]
 [   0    0    0 1182]
 [   0    0    0  798]
 [   0    0    0  331]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.14      1.00      0.24       331

    accuracy                           0.14      2413
   macro avg       0.03      0.25      0.06      2413
weighted avg       0.02      0.14      0.03      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 2052    0    0]
 [   0  268    0    0]
 [   0   90    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      1.00      0.92      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.85      2413
   macro avg       0.21      0.25      0.23      2413
weighted avg       0.72      0.85      0.78      2413

lstm + distilbert-base-multilingual-cased
[17:00:42] task: task-2                                                                                my_import.py:127
           model_type: lstm                                                                            my_import.py:127
           model_name: distilbert-base-multilingual-cased                                              my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           hidden_size: 128                                                                            my_import.py:127
           num_layers: 1                                                                               my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/lstm_distilbert-base-multilingual-cased                        my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/lstm_distilbert-base-multilingual-cased_19.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 51.0149, 0/1 Loss: 1.0000, Hamming Loss: 0.6433, EMR: 0.0000, Acc: 0.7370, F1: 0.5318, Precision: 0.5184, Recall: 0.5727
Confusion Matrix of title aspect
[[  0   5   4   0]
 [  0 528 318   0]
 [  0 204 145   0]
 [  0   2   1   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.71      0.62      0.67       846
           2       0.31      0.42      0.35       349
           3       0.00      0.00      0.00         3

    accuracy                           0.56      1207
   macro avg       0.26      0.26      0.26      1207
weighted avg       0.59      0.56      0.57      1207

Confusion Matrix of desc aspect
[[  2   0   0   0]
 [745   0   0   0]
 [459   0   0   0]
 [  1   0   0   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      1.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.00      0.00      0.00       459
           3       0.00      0.00      0.00         1

    accuracy                           0.00      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.00      0.00      1207

Confusion Matrix of company aspect
[[  0   0   0  56]
 [  0   0   0 586]
 [  0   0   0 399]
 [  0   0   0 166]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.14      1.00      0.24       166

    accuracy                           0.14      1207
   macro avg       0.03      0.25      0.06      1207
weighted avg       0.02      0.14      0.03      1207

Confusion Matrix of other aspect
[[837   1 187]
 [ 68  20  42]
 [ 22   6  24]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.90      0.82      0.86      1025
           2       0.74      0.15      0.25       130
           3       0.09      0.46      0.16        52

    accuracy                           0.73      1207
   macro avg       0.58      0.48      0.42      1207
weighted avg       0.85      0.73      0.76      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 101.9222, 0/1 Loss: 1.0000, Hamming Loss: 0.6450, EMR: 0.0000, Acc: 0.7367, F1: 0.5326, Precision: 0.5208, Recall: 0.5716
Confusion Matrix of title aspect
[[   0   15    8    0]
 [   0 1075  611    0]
 [   0  426  274    0]
 [   0    1    3    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        23
           1       0.71      0.64      0.67      1686
           2       0.31      0.39      0.34       700
           3       0.00      0.00      0.00         4

    accuracy                           0.56      2413
   macro avg       0.25      0.26      0.25      2413
weighted avg       0.58      0.56      0.57      2413

Confusion Matrix of desc aspect
[[   0    0    0]
 [1451    0    0]
 [ 962    0    0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
           1       0.00      0.00      0.00    1451.0
           2       0.00      0.00      0.00     962.0

    accuracy                           0.00    2413.0
   macro avg       0.00      0.00      0.00    2413.0
weighted avg       0.00      0.00      0.00    2413.0

Confusion Matrix of company aspect
[[   0    0    0  102]
 [   0    0    0 1182]
 [   0    0    0  798]
 [   0    0    0  331]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.14      1.00      0.24       331

    accuracy                           0.14      2413
   macro avg       0.03      0.25      0.06      2413
weighted avg       0.02      0.14      0.03      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 1663   12  377]
 [   0  144   49   75]
 [   0   46   10   34]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.90      0.81      0.85      2052
           2       0.69      0.18      0.29       268
           3       0.07      0.38      0.12        90

    accuracy                           0.72      2413
   macro avg       0.41      0.34      0.31      2413
weighted avg       0.84      0.72      0.76      2413

======= Training CNN =======

cnn + vinai/phobert-base
[17:01:14] task: task-2                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: vinai/phobert-base                                                              my_import.py:127
           padding_len: 200                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 20                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/cnn_phobert-base                                               my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Training ...
Epoch 1/20:   0%|          | 0/264 [00:00<?, ?it/s]
Epoch 1/20, Loss: 367.5631, 0/1 Loss: 0.9972, Hamming Loss: 0.6842, EMR: 0.0028, Acc: 0.5945, F1: 0.4835, Precision: 0.5959, Recall: 0.4647
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 53.0481, 0/1 Loss: 0.9843, Hamming Loss: 0.4830, EMR: 0.0157, Acc: 0.9861, F1: 0.6413, Precision: 0.5635, Recall: 0.7683



======= Evaluating CNN ======

cnn + vinai/phobert-base
[18:19:51] task: task-2                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: vinai/phobert-base                                                              my_import.py:127
           padding_len: 200                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/cnn_phobert-base                                               my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/cnn_phobert-base_1.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 52.9692, 0/1 Loss: 0.9934, Hamming Loss: 0.5058, EMR: 0.0066, Acc: 0.7592, F1: 0.6474, Precision: 0.7477, Recall: 0.5854
Confusion Matrix of title aspect
[[  0   9   0   0]
 [  0 846   0   0]
 [  0 349   0   0]
 [  0   3   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.70      1.00      0.82       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.70      1207
   macro avg       0.18      0.25      0.21      1207
weighted avg       0.49      0.70      0.58      1207

Confusion Matrix of desc aspect
[[  0   0   2   0]
 [  0   0 745   0]
 [  0   0 459   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.38      1.00      0.55       459
           3       0.00      0.00      0.00         1

    accuracy                           0.38      1207
   macro avg       0.10      0.25      0.14      1207
weighted avg       0.14      0.38      0.21      1207

Confusion Matrix of company aspect
[[ 56   0   0   0]
 [586   0   0   0]
 [399   0   0   0]
 [166   0   0   0]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.05      1.00      0.09        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.00      0.00      0.00       166

    accuracy                           0.05      1207
   macro avg       0.01      0.25      0.02      1207
weighted avg       0.00      0.05      0.00      1207

Confusion Matrix of other aspect
[[1025    0    0]
 [ 130    0    0]
 [  52    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.85      1.00      0.92      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.85      1207
   macro avg       0.28      0.33      0.31      1207
weighted avg       0.72      0.85      0.78      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 105.5996, 0/1 Loss: 0.9892, Hamming Loss: 0.5025, EMR: 0.0108, Acc: 0.7578, F1: 0.6461, Precision: 0.7473, Recall: 0.5829
Confusion Matrix of title aspect
[[   0   23    0    0]
 [   0 1686    0    0]
 [   0  700    0    0]
 [   0    4    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        23
           1       0.70      1.00      0.82      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.70      2413
   macro avg       0.17      0.25      0.21      2413
weighted avg       0.49      0.70      0.57      2413

Confusion Matrix of desc aspect
[[   0 1451]
 [   0  962]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.00      0.00      0.00      1451
           2       0.40      1.00      0.57       962

    accuracy                           0.40      2413
   macro avg       0.20      0.50      0.29      2413
weighted avg       0.16      0.40      0.23      2413

Confusion Matrix of company aspect
[[ 102    0    0    0]
 [1182    0    0    0]
 [ 798    0    0    0]
 [ 331    0    0    0]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.04      1.00      0.08       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.00      0.00      0.00       331

    accuracy                           0.04      2413
   macro avg       0.01      0.25      0.02      2413
weighted avg       0.00      0.04      0.00      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 2052    0    0]
 [   0  268    0    0]
 [   0   90    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      1.00      0.92      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.85      2413
   macro avg       0.21      0.25      0.23      2413
weighted avg       0.72      0.85      0.78      2413

cnn + uitnlp/visobert
[18:20:29] task: task-2                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: uitnlp/visobert                                                                 my_import.py:127
           padding_len: 400                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/cnn_visobert                                                   my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/visobert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

model_weight_path: ./models/task_2/cnn_visobert_0.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 53.4441, 0/1 Loss: 0.9992, Hamming Loss: 0.5294, EMR: 0.0008, Acc: 0.7370, F1: 0.6357, Precision: 0.7365, Recall: 0.5727
Confusion Matrix of title aspect
[[  0   9   0   0]
 [  0 846   0   0]
 [  0 349   0   0]
 [  0   3   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.70      1.00      0.82       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.70      1207
   macro avg       0.18      0.25      0.21      1207
weighted avg       0.49      0.70      0.58      1207

Confusion Matrix of desc aspect
[[  2   0   0   0]
 [745   0   0   0]
 [459   0   0   0]
 [  1   0   0   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      1.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.00      0.00      0.00       459
           3       0.00      0.00      0.00         1

    accuracy                           0.00      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.00      0.00      1207

Confusion Matrix of company aspect
[[  0   0  56   0]
 [  0   0 586   0]
 [  0   0 399   0]
 [  0   0 166   0]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.33      1.00      0.50       399
           3       0.00      0.00      0.00       166

    accuracy                           0.33      1207
   macro avg       0.08      0.25      0.12      1207
weighted avg       0.11      0.33      0.16      1207

Confusion Matrix of other aspect
[[1025    0    0]
 [ 130    0    0]
 [  52    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.85      1.00      0.92      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.85      1207
   macro avg       0.28      0.33      0.31      1207
weighted avg       0.72      0.85      0.78      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 106.8580, 0/1 Loss: 1.0000, Hamming Loss: 0.5300, EMR: 0.0000, Acc: 0.7367, F1: 0.6352, Precision: 0.7367, Recall: 0.5716
Confusion Matrix of title aspect
[[   0   23    0    0]
 [   0 1686    0    0]
 [   0  700    0    0]
 [   0    4    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        23
           1       0.70      1.00      0.82      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.70      2413
   macro avg       0.17      0.25      0.21      2413
weighted avg       0.49      0.70      0.57      2413

Confusion Matrix of desc aspect
[[   0    0    0]
 [1451    0    0]
 [ 962    0    0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
           1       0.00      0.00      0.00    1451.0
           2       0.00      0.00      0.00     962.0

    accuracy                           0.00    2413.0
   macro avg       0.00      0.00      0.00    2413.0
weighted avg       0.00      0.00      0.00    2413.0

Confusion Matrix of company aspect
[[   0    0  102    0]
 [   0    0 1182    0]
 [   0    0  798    0]
 [   0    0  331    0]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.33      1.00      0.50       798
           3       0.00      0.00      0.00       331

    accuracy                           0.33      2413
   macro avg       0.08      0.25      0.12      2413
weighted avg       0.11      0.33      0.16      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 2052    0    0]
 [   0  268    0    0]
 [   0   90    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      1.00      0.92      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.85      2413
   macro avg       0.21      0.25      0.23      2413
weighted avg       0.72      0.85      0.78      2413

cnn + uitnlp/CafeBERT
[18:21:18] task: task-2                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: uitnlp/CafeBERT                                                                 my_import.py:127
           padding_len: 300                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/cnn_CafeBERT                                                   my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

model_weight_path: ./models/task_2/cnn_CafeBERT_0.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 53.1044, 0/1 Loss: 0.9594, Hamming Loss: 0.5860, EMR: 0.0406, Acc: 0.9861, F1: 0.5926, Precision: 0.4931, Recall: 0.7683
Confusion Matrix of title aspect
[[  0   0   9   0]
 [  0   0 846   0]
 [  0   0 349   0]
 [  0   0   3   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.00      0.00      0.00       846
           2       0.29      1.00      0.45       349
           3       0.00      0.00      0.00         3

    accuracy                           0.29      1207
   macro avg       0.07      0.25      0.11      1207
weighted avg       0.08      0.29      0.13      1207

Confusion Matrix of desc aspect
[[  0   0   2   0]
 [  0   0 745   0]
 [  0   0 459   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.38      1.00      0.55       459
           3       0.00      0.00      0.00         1

    accuracy                           0.38      1207
   macro avg       0.10      0.25      0.14      1207
weighted avg       0.14      0.38      0.21      1207

Confusion Matrix of company aspect
[[  0   0   0  56]
 [  0   0   0 586]
 [  0   0   0 399]
 [  0   0   0 166]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.14      1.00      0.24       166

    accuracy                           0.14      1207
   macro avg       0.03      0.25      0.06      1207
weighted avg       0.02      0.14      0.03      1207

Confusion Matrix of other aspect
[[1025    0    0]
 [ 130    0    0]
 [  52    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.85      1.00      0.92      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.85      1207
   macro avg       0.28      0.33      0.31      1207
weighted avg       0.72      0.85      0.78      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 105.9354, 0/1 Loss: 0.9602, Hamming Loss: 0.5809, EMR: 0.0398, Acc: 0.9867, F1: 0.5926, Precision: 0.4934, Recall: 0.7668
Confusion Matrix of title aspect
[[   0    0   23    0]
 [   0    0 1686    0]
 [   0    0  700    0]
 [   0    0    4    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        23
           1       0.00      0.00      0.00      1686
           2       0.29      1.00      0.45       700
           3       0.00      0.00      0.00         4

    accuracy                           0.29      2413
   macro avg       0.07      0.25      0.11      2413
weighted avg       0.08      0.29      0.13      2413

Confusion Matrix of desc aspect
[[   0 1451]
 [   0  962]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.00      0.00      0.00      1451
           2       0.40      1.00      0.57       962

    accuracy                           0.40      2413
   macro avg       0.20      0.50      0.29      2413
weighted avg       0.16      0.40      0.23      2413

Confusion Matrix of company aspect
[[   0    0    0  102]
 [   0    0    0 1182]
 [   0    0    0  798]
 [   0    0    0  331]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.14      1.00      0.24       331

    accuracy                           0.14      2413
   macro avg       0.03      0.25      0.06      2413
weighted avg       0.02      0.14      0.03      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 2052    0    0]
 [   0  268    0    0]
 [   0   90    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      1.00      0.92      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.85      2413
   macro avg       0.21      0.25      0.23      2413
weighted avg       0.72      0.85      0.78      2413

cnn + xlm-roberta-base
[18:22:37] task: task-2                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: xlm-roberta-base                                                                my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/cnn_xlm-roberta-base                                           my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/cnn_xlm-roberta-base_0.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 53.6626, 0/1 Loss: 1.0000, Hamming Loss: 0.9151, EMR: 0.0000, Acc: 0.2390, F1: 0.2618, Precision: 0.4768, Recall: 0.1830
Confusion Matrix of title aspect
[[  9   0   0   0]
 [846   0   0   0]
 [349   0   0   0]
 [  3   0   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.01         9
           1       0.00      0.00      0.00       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.01      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.01      0.00      1207

Confusion Matrix of desc aspect
[[  2   0   0   0]
 [745   0   0   0]
 [459   0   0   0]
 [  1   0   0   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      1.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.00      0.00      0.00       459
           3       0.00      0.00      0.00         1

    accuracy                           0.00      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.00      0.00      1207

Confusion Matrix of company aspect
[[  0   0  56   0]
 [  0   0 586   0]
 [  0   0 399   0]
 [  0   0 166   0]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.33      1.00      0.50       399
           3       0.00      0.00      0.00       166

    accuracy                           0.33      1207
   macro avg       0.08      0.25      0.12      1207
weighted avg       0.11      0.33      0.16      1207

Confusion Matrix of other aspect
[[   0    0    0    0]
 [1025    0    0    0]
 [ 130    0    0    0]
 [  52    0    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
           1       0.00      0.00      0.00    1025.0
           2       0.00      0.00      0.00     130.0
           3       0.00      0.00      0.00      52.0

    accuracy                           0.00    1207.0
   macro avg       0.00      0.00      0.00    1207.0
weighted avg       0.00      0.00      0.00    1207.0

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 107.3684, 0/1 Loss: 1.0000, Hamming Loss: 0.9146, EMR: 0.0000, Acc: 0.2403, F1: 0.2631, Precision: 0.4789, Recall: 0.1839
Confusion Matrix of title aspect
[[  23    0    0    0]
 [1686    0    0    0]
 [ 700    0    0    0]
 [   4    0    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.02        23
           1       0.00      0.00      0.00      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.01      2413
   macro avg       0.00      0.25      0.00      2413
weighted avg       0.00      0.01      0.00      2413

Confusion Matrix of desc aspect
[[   0    0    0]
 [1451    0    0]
 [ 962    0    0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
           1       0.00      0.00      0.00    1451.0
           2       0.00      0.00      0.00     962.0

    accuracy                           0.00    2413.0
   macro avg       0.00      0.00      0.00    2413.0
weighted avg       0.00      0.00      0.00    2413.0

Confusion Matrix of company aspect
[[   0    0  102    0]
 [   0    0 1182    0]
 [   0    0  798    0]
 [   0    0  331    0]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.33      1.00      0.50       798
           3       0.00      0.00      0.00       331

    accuracy                           0.33      2413
   macro avg       0.08      0.25      0.12      2413
weighted avg       0.11      0.33      0.16      2413

Confusion Matrix of other aspect
[[   3    0    0    0]
 [2052    0    0    0]
 [ 268    0    0    0]
 [  90    0    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      1.00      0.00         3
           1       0.00      0.00      0.00      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.00      2413
   macro avg       0.00      0.25      0.00      2413
weighted avg       0.00      0.00      0.00      2413

cnn + bert-base-multilingual-cased
[18:23:28] task: task-2                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: bert-base-multilingual-cased                                                    my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/cnn_bert-base-multilingual-cased                               my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/cnn_bert-base-multilingual-cased_0.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 52.5645, 0/1 Loss: 1.0000, Hamming Loss: 0.6564, EMR: 0.0000, Acc: 0.7397, F1: 0.5227, Precision: 0.4920, Recall: 0.5746
Confusion Matrix of title aspect
[[  9   0   0   0]
 [846   0   0   0]
 [349   0   0   0]
 [  3   0   0   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.01         9
           1       0.00      0.00      0.00       846
           2       0.00      0.00      0.00       349
           3       0.00      0.00      0.00         3

    accuracy                           0.01      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.01      0.00      1207

Confusion Matrix of desc aspect
[[  0   0   2   0]
 [  0   0 745   0]
 [  0   0 459   0]
 [  0   0   1   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.38      1.00      0.55       459
           3       0.00      0.00      0.00         1

    accuracy                           0.38      1207
   macro avg       0.10      0.25      0.14      1207
weighted avg       0.14      0.38      0.21      1207

Confusion Matrix of company aspect
[[  0   0   0  56]
 [  0   0   0 586]
 [  0   0   0 399]
 [  0   0   0 166]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.14      1.00      0.24       166

    accuracy                           0.14      1207
   macro avg       0.03      0.25      0.06      1207
weighted avg       0.02      0.14      0.03      1207

Confusion Matrix of other aspect
[[1025    0    0]
 [ 130    0    0]
 [  52    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.85      1.00      0.92      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.85      1207
   macro avg       0.28      0.33      0.31      1207
weighted avg       0.72      0.85      0.78      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 104.7621, 0/1 Loss: 0.9992, Hamming Loss: 0.6511, EMR: 0.0008, Acc: 0.7415, F1: 0.5231, Precision: 0.4927, Recall: 0.5741
Confusion Matrix of title aspect
[[  23    0    0    0]
 [1686    0    0    0]
 [ 700    0    0    0]
 [   4    0    0    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.01      1.00      0.02        23
           1       0.00      0.00      0.00      1686
           2       0.00      0.00      0.00       700
           3       0.00      0.00      0.00         4

    accuracy                           0.01      2413
   macro avg       0.00      0.25      0.00      2413
weighted avg       0.00      0.01      0.00      2413

Confusion Matrix of desc aspect
[[   0 1451]
 [   0  962]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           1       0.00      0.00      0.00      1451
           2       0.40      1.00      0.57       962

    accuracy                           0.40      2413
   macro avg       0.20      0.50      0.29      2413
weighted avg       0.16      0.40      0.23      2413

Confusion Matrix of company aspect
[[   0    0    0  102]
 [   0    0    0 1182]
 [   0    0    0  798]
 [   0    0    0  331]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.14      1.00      0.24       331

    accuracy                           0.14      2413
   macro avg       0.03      0.25      0.06      2413
weighted avg       0.02      0.14      0.03      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 2052    0    0]
 [   0  268    0    0]
 [   0   90    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      1.00      0.92      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.85      2413
   macro avg       0.21      0.25      0.23      2413
weighted avg       0.72      0.85      0.78      2413

cnn + distilbert-base-multilingual-cased
[18:24:17] task: task-2                                                                                my_import.py:127
           model_type: cnn                                                                             my_import.py:127
           model_name: distilbert-base-multilingual-cased                                              my_import.py:127
           padding_len: 500                                                                            my_import.py:125
           batch_size: 32                                                                              my_import.py:127
           learning_rate: 0.001                                                                        my_import.py:127
           epochs: 10                                                                                  my_import.py:127
           fine_tune: True                                                                             my_import.py:127
           num_channels: 768                                                                           my_import.py:127
           kernel_size: 256                                                                            my_import.py:127
           padding: 32                                                                                 my_import.py:127
           device: cuda                                                                                my_import.py:127
           saving_path: ./models/task_2/cnn_distilbert-base-multilingual-cased                         my_import.py:127
           train_shape: (8444, 28)                                                                     my_import.py:127
           dev_shape: (1207, 28)                                                                       my_import.py:127
           test_shape: (2413, 28)                                                                      my_import.py:127

model_weight_path: ./models/task_2/cnn_distilbert-base-multilingual-cased_0.pth
Loading model weight successfully!

Evaluation on dev test
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]
Evaluation, Loss: 53.4269, 0/1 Loss: 1.0000, Hamming Loss: 0.6806, EMR: 0.0000, Acc: 0.7370, F1: 0.5215, Precision: 0.4910, Recall: 0.5727
Confusion Matrix of title aspect
[[  0   0   9   0]
 [  0   0 846   0]
 [  0   0 349   0]
 [  0   0   3   0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         9
           1       0.00      0.00      0.00       846
           2       0.29      1.00      0.45       349
           3       0.00      0.00      0.00         3

    accuracy                           0.29      1207
   macro avg       0.07      0.25      0.11      1207
weighted avg       0.08      0.29      0.13      1207

Confusion Matrix of desc aspect
[[  2   0   0   0]
 [745   0   0   0]
 [459   0   0   0]
 [  1   0   0   0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      1.00      0.00         2
           1       0.00      0.00      0.00       745
           2       0.00      0.00      0.00       459
           3       0.00      0.00      0.00         1

    accuracy                           0.00      1207
   macro avg       0.00      0.25      0.00      1207
weighted avg       0.00      0.00      0.00      1207

Confusion Matrix of company aspect
[[  0   0   0  56]
 [  0   0   0 586]
 [  0   0   0 399]
 [  0   0   0 166]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        56
           1       0.00      0.00      0.00       586
           2       0.00      0.00      0.00       399
           3       0.14      1.00      0.24       166

    accuracy                           0.14      1207
   macro avg       0.03      0.25      0.06      1207
weighted avg       0.02      0.14      0.03      1207

Confusion Matrix of other aspect
[[1025    0    0]
 [ 130    0    0]
 [  52    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           1       0.85      1.00      0.92      1025
           2       0.00      0.00      0.00       130
           3       0.00      0.00      0.00        52

    accuracy                           0.85      1207
   macro avg       0.28      0.33      0.31      1207
weighted avg       0.72      0.85      0.78      1207

Evaluation on test test
Evaluation:   0%|          | 0/76 [00:00<?, ?it/s]
Evaluation, Loss: 106.8090, 0/1 Loss: 1.0000, Hamming Loss: 0.6806, EMR: 0.0000, Acc: 0.7367, F1: 0.5212, Precision: 0.4912, Recall: 0.5716
Confusion Matrix of title aspect
[[   0    0   23    0]
 [   0    0 1686    0]
 [   0    0  700    0]
 [   0    0    4    0]]
Classification Report for title aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        23
           1       0.00      0.00      0.00      1686
           2       0.29      1.00      0.45       700
           3       0.00      0.00      0.00         4

    accuracy                           0.29      2413
   macro avg       0.07      0.25      0.11      2413
weighted avg       0.08      0.29      0.13      2413

Confusion Matrix of desc aspect
[[   0    0    0]
 [1451    0    0]
 [ 962    0    0]]
Classification Report for desc aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       0.0
           1       0.00      0.00      0.00    1451.0
           2       0.00      0.00      0.00     962.0

    accuracy                           0.00    2413.0
   macro avg       0.00      0.00      0.00    2413.0
weighted avg       0.00      0.00      0.00    2413.0

Confusion Matrix of company aspect
[[   0    0    0  102]
 [   0    0    0 1182]
 [   0    0    0  798]
 [   0    0    0  331]]
Classification Report for company aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       102
           1       0.00      0.00      0.00      1182
           2       0.00      0.00      0.00       798
           3       0.14      1.00      0.24       331

    accuracy                           0.14      2413
   macro avg       0.03      0.25      0.06      2413
weighted avg       0.02      0.14      0.03      2413

Confusion Matrix of other aspect
[[   0    3    0    0]
 [   0 2052    0    0]
 [   0  268    0    0]
 [   0   90    0    0]]
Classification Report for other aspect
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.85      1.00      0.92      2052
           2       0.00      0.00      0.00       268
           3       0.00      0.00      0.00        90

    accuracy                           0.85      2413
   macro avg       0.21      0.25      0.23      2413
weighted avg       0.72      0.85      0.78      2413

